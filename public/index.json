[
{
	"uri": "//localhost:1313/",
	"title": "Main Page",
	"tags": [],
	"description": "",
	"content": " Secure DevOps with AWS \u0026amp; Sysdig Welcome Welcome to the Secure DevOps with AWS \u0026amp; Sysdig hands-on workshop.\nIn this workshop, you will learn how to securely run cloud applications in production by automating AWS Fargate and ECR image scanning directly in your AWS environment.\nYou will also discover how to improve the security of your cloud infrastructure using AWS CloudTrail and Sysdig CloudConnector. So not only are the applications secure, but so is the cloud infrastructure on which they depend! The topics we\u0026rsquo;ll discuss are:\n Introduction to Security  Image Scanning Inline Scanning  Amazon ECR Security Amazon ECS and Fargate Security Infrastructure Runtime security  Objectives The objective of this workshop is to familiarize users with the installation, configuration and usage of the following Sysdig security tools specific to AWS:\n Amazon ECR image scanning\n Amazon Fargate automated image scanning\n Amazon CloudTrail runtime security\n  Who should take this workshop?  Infrastructure Engineers\n DevOps Engineers\n Solutions Architects  Software Developers\n SREs\n Technical leads\n  "
},
{
	"uri": "//localhost:1313/00_introduction/03_image_scanning.html",
	"title": "Image Scanning Overview",
	"tags": [],
	"description": "",
	"content": "Sysdig Secure provides a comprehensive suite of tools to enhance and compliance across your application\u0026rsquo;s ecosystem. One critical part of this is scanning the images in your registry.\nSysdig’s ImageVision technology identifies vulnerabilities and misconfigurations by automating scanning within CI/CD pipelines and registries, as well as implementing registry scanning inline. It also blocks vulnerabilities pre-production, monitors for new CVEs at runtime, and helps you map a critical vulnerability back to an application and dev team.\nAn image scanner inspects a container\u0026rsquo;s content to detect threats such as unencrypted passwords, known vulnerabilities, exposed ports, etc. You can implement scanning best practices on several phases of your DevOps pipeline, blocking threats before they are deployed into production, and without adding extra overhead.\nSysdig Secure manages every aspect of the container scan. With Sysdig you can define image scanning policies to validate a container\u0026rsquo;s content against vulnerability databases, and search for misconfigurations like running as a privileged user, unnecessary open ports, or leaked credentials.\nNot only can you create multiple policies that determine what the scan is looking for, but also when to implement it. For example, in your CI/CD pipeline you may wish to use the test site https://sandbox.payment-engine.com/ during your automated QA tests, but when building containers for production this must be the live https://live.payment-engine.com. Or, you may wish to scan specifically for PSI or NIST compliance in a production site.\nFurther, you may wish to scan existing running containers for zero day vulnerabilities that have recently been detected.\nIn either case, the output of the scan will be sent back to Sysdig from where you can browse the results or run reports.\nAlthough containers may be ingested into another system in order to be scanned, for example a Sysdig Secure backend, it\u0026rsquo;s considered best practice to scan the image \u0026lsquo;inline\u0026rsquo;, i.e. locally in its current location.\nWith inline scanning, the contents of your containers will never leave your infrastructure. This protects your privacy and prevents credentials for repositories from leaking. It may also be a requirement when security concerns require an air-gapped environment.\nFurther, from an architectural standpoint, it is more scalable to have images scanned at the edge rather than sent to a central location.\n"
},
{
	"uri": "//localhost:1313/00_introduction/04_inline_scanning.html",
	"title": "Image Scanning Technical Description",
	"tags": [],
	"description": "",
	"content": " There are two general approaches to scanning images in Sysdig - backend scanning or inline scanning. The reasons why you might choose one over the other is best explained by an understanding of how scanning works under the hood.\n-- With Sysdig, there are two phases in scanning an image\n Analysis of contents Evaluation against policies and vulnerabilities  Phase 1 - Analysis of Contents During the analysis phase of the scan, the worker first loads the image. Each image is built upon a series of other images, called \u0026lsquo;layers\u0026rsquo;, each one referred to by specific SHA value in the manifest file. Each layer is pulled down, they are then “flattened”, and the composition of all layers is analysed and a complete list of all the files, packages, package versions, etc across all the layers is generated.\nThis phase of the scan is quite process-heavy and accounts for approximately 90% of the Time/CPU consumed during the entire scan, and the output of this is a JSON document containing metadata on all aspects of the image.\nDuring an inline scan, this phase happens in the image\u0026rsquo;s environment - in a CI/CD pipeline, by an Admission Controller, or even on a Kubernetes worker node, as illustrated below.\nGoing A Little Deeper\u0026hellip; The scanner process uses the Anchore engine and runs between 15 and 20 different analysers, each performing different functions. Some of these analysers create a bill of materials for the image (operating system and non-operating system packages), while others retrieve file contents, file sizes, search for secrets, open ports, etc. Each analyser generates a JSON report containing metadata, all of which are then combined.\nTo give you a better idea of how this looks, below is a sample of the data generated in the analysis phase.\nExpand here to view some some sample output to give you some visualisation of how this looks  -- { \u0026#34;document\u0026#34;: [ { \u0026#34;image\u0026#34;: { \u0026#34;imageId\u0026#34;: \u0026#34;f35646e83998b844c3f067e5a2cff84cdf0967627031aeda3042d78996b68d35\u0026#34;, \u0026#34;imagedata\u0026#34;: { \u0026#34;analysis_report\u0026#34;: { \u0026#34;analyzer_meta\u0026#34;: { \u0026#34;analyzer_meta\u0026#34;: { \u0026#34;base\u0026#34;: { \u0026#34;DISTRO\u0026#34;: \u0026#34;debian\u0026#34;, \u0026#34;DISTROVERS\u0026#34;: \u0026#34;10\u0026#34;, \u0026#34;LIKEDISTRO\u0026#34;: \u0026#34;debian\u0026#34; } } }, \u0026#34;file_checksums\u0026#34;: { \u0026#34;files.md5sums\u0026#34;: { \u0026#34;base\u0026#34;: { \u0026#34;/bin\u0026#34;: \u0026#34;DIRECTORY_OR_OTHER\u0026#34;, \u0026#34;/bin/bash\u0026#34;: \u0026#34;4600132e6a7ae0d451566943a9e79736\u0026#34;, \u0026#34;/bin/cat\u0026#34;: \u0026#34;44b8726219e0d2929e9150210bfbb544\u0026#34;, \u0026#34;/bin/chgrp\u0026#34;: \u0026#34;2befb2d66eee50af3fd5eb0b30102841\u0026#34;, \u0026#34;/bin/chmod\u0026#34;: \u0026#34;737ae4345da6e93c44fe9b11b12defe1\u0026#34;, \u0026#34;/bin/chown\u0026#34;: \u0026#34;8680c8e619194af847c009a97fd4ebe2\u0026#34;, \u0026#34;/bin/cp\u0026#34;: \u0026#34;d38d5be99452fb23cce11fc7756c1594\u0026#34;, \u0026#34;/bin/dash\u0026#34;: \u0026#34;895aea5b87d9d6cbd73537a9b2d45cff\u0026#34;, \u0026#34;/bin/date\u0026#34;: \u0026#34;b175b76c42bf04d764f3f5d7e4f3c69c\u0026#34;, \u0026#34;/bin/dd\u0026#34;: \u0026#34;1f90de0a1b75febeda1936a1ed9e1066\u0026#34;, \u0026#34;/bin/df\u0026#34;: \u0026#34;b50d93d2ab75977d129baf0078becb96\u0026#34;, \u0026#34;/bin/dir\u0026#34;: \u0026#34;3c76bcda677ed3ff9901d6e770ebca3d\u0026#34;, \u0026#34;/bin/dmesg\u0026#34;: \u0026#34;ea95ebcd2794014a5f933f7b6434e31c\u0026#34;, ... -- You can see each binary, file etc is specifically referenced with a md5 hash next to each entry which relates to its version etc.\nThe results of this analysis are combined into a single JSON analysis report, or metadata document, and it is this metadata document that is used to evaluate the scan against the defines security policy.\nFor a backend scan, this process all happens within Sysdig, however during an \u0026lsquo;inline scan\u0026rsquo;, this metadata is then forwarded to the Sysdig Backend for evaluation using the API - this is the reason you must supply the Sysdig Secure API Token later in this workshop!\nPhase 2 - Evaluation Once the Sysdig Backend retrieves the metadata it is checked against the assigned policy definitions as well as the vulnerability database. A Sysdig Secure policy is a combination of rules about activities an enterprise wants to detect in an environment, the actions that should be taken if the policy rule is breached, and potentially the notifications that should be sent. These policies are configured through the Sysdig UI, and may differ from image to image.\nIndividual policy rules may relate to\n Open ports File permissions Exposed passwords etc  A number of policies are delivered out-of-the-box and can be used as-is, duplicated, or edited as needed. These relate specifically to \u0026lsquo;PCI\u0026rsquo; and \u0026lsquo;NIST 800-190\u0026rsquo; compliance, as well as general Dockerfile best practices. You can also create policies from scratch, using either predefined rules or creating custom rules.\nInline Scanning vs Backend Scanning With Backend Scanning, both phases of the scan, i.e. the analysis of contents followed by the evaluation against policies and vulnerabilities, are performed on Sysdig\u0026rsquo;s servers. This requires that images be transferred to Sysdig to be scanned and evaluated, therefore Sysdig must store your repository\u0026rsquo;s credentials in order to have access to it. This may be problematic in a secure environment and/or when you\u0026rsquo;re using SaaS.\nHowever, with Inline Scanning the scan and subsequent analysis occur where the image resides, maybe as part of a CI/CD pipeline, or within your cloud environment, for example with ECR. In this case Sysdig does not need access to your repository and only the metadata is sent back to the Sysdig backend, hence no registry keys are exposed to Sysdig.\nInline Scanning is considered best practice and the better approach to scanning over backend scanning. The benefits of scanning inline include\n Images don\u0026rsquo;t leave their own environment SaaS users don\u0026rsquo;t send images and proprietary code to Sysdig\u0026rsquo;s SaaS service Registries don\u0026rsquo;t have to be exposed Images can be scanned in parallel more easily Images can be scanned before they hit the registry, which can cut down on registry costs and simplify the build pipeline Existing scan metadata can be checked against new vulnerabilities, so images do no need to be rescanned, for example upon detection of zero-day vulnerabilities  "
},
{
	"uri": "//localhost:1313/00_introduction/05_fargate_ecs_sec.html",
	"title": "AWS Fargate and ECS Security",
	"tags": [],
	"description": "",
	"content": "Amazon Elastic Container Service (Amazon ECS) is a fully managed container orchestration service based on Kubernetes, allowing developers to run applications without the need to configure the required running environment. Amazon ECS is fully integrated with the Docker container registry AWS ECR.\nAWS Fargate is a serverless compute engine for containers that removes the need to provision and manage servers. Fargate works alongside Amazon ECS (as well as Amazon EKS) to allocate the correct amount of compute resources for your application no matter the load, hence eliminating the need to choose instance types or scale cluster capacity. You only pay for the resources required to run your containers, so there is no over-provisioning and paying for additional servers.\nAWS Fargate and ECS both allow you to deploy containerized workloads quickly. Those services are so convenient that many people leave them unattended, risking exposure to vulnerabilities inside their containers that can exfiltrate secrets, compromise business data, impact performance, and increase their AWS costs.\nFor example, think of some credentials mistakenly included in an image, later deployed on Fargate. They will be exposed to anyone with access to the image (think on the repository), or to the Fargate service.\nOr consider a known vulnerability. Imagine you deploy a Fargate task to manage your API, and that it uses an old HTTP library version that ignores the setting to limit a request size. That could be catastrophic! Say you expect requests no bigger than 1MB, but a malicious actor exploits this vulnerability to send requests as big as 80GB. This will absolutely take a toll in your AWS bill, and might cause your service to throttle.\nThose are serious threats. In this workshop you will see how Sysdig helps circumvent these threats by automating the scanning of images both at rest in Amazon ECR, as well as in ECS/Fargate, for known vulnerabilities and issues.\n"
},
{
	"uri": "//localhost:1313/00_introduction.html",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": " Workshop Overview It is extremely important to maintain a high level of security \u0026amp; compliance in your entire application environment. Not doing so can result in your system being compromised. This can incur significant costs and can lead to commercial \u0026amp; business issues, and failed compliance tests leading to a loss of trust with customers and monetary fines and/or settlement fees.\nIn a cloud native environment, the security \u0026amp; compliance posture of your application is dependent largely upon the security of your containers, but not exclusively - it also depends upon the infrastructure upon which it runs.\nSysdig Secure embeds security and compliance into the build, run and respond stages of the Kubernetes lifecycle. Manage cloud security risk by integrating image scanning, threat prevention, detection and incident response into your secure DevOps workflow.\nIn this workshop, you will learn how image scanning can provide the security insights you need without affecting the level of flexibility you desire.\nIn particular, we\u0026rsquo;ll guide you on how to implement ECS Fargate image scanning with Sysdig Secure. The resulting solution will automatically scan any container image instance that is executed, and will warn you with reports about any vulnerabilities or misconfigurations in your workload. It will do this without leaving your AWS workflow, and without data leaving your AWS infrastructure.\nWe will also look at how to use Falco to perform \u0026lsquo;runtime\u0026rsquo; security and compliance in the context of your AWS environment using Sysdig\u0026rsquo;s CloudConnector\u0026rsquo;s integration with AWS CloudTrail.\nExpected Duration:\n 2-3 Hours  Target Audience:\n Cloud Architects Security Architects SysAdmins Developers  Some experience/knowledge with AWS is helpful but the workshop will provide instructions to run through the workshop with no issues and if you are attending one of our live workshop sessions there will be folks to help assist with issues that come up\n"
},
{
	"uri": "//localhost:1313/00_introduction/06_infra_runtime_sec.html",
	"title": "Infrastructure Runtime Security",
	"tags": [],
	"description": "",
	"content": "In the same way image scanning gives you visibility of vulnerabilities and threats pertaining specifically to an application\u0026rsquo;s containers, infrastructure scanning gives visibility of potential issues emanating from the environment on which these containers run.\nAWS provides a rich environment upon which to base your application, but it\u0026rsquo;s not without its risks. There are many places where bad actors can create harm, for example exposing data by making S3 buckets public, deleting bucket encryption, disabling MFA for an account, adding/removing IAM policies.\nFalco is an open source threat detection language that is widely used to detect and alert on runtime abnormalities, and can also be used to detect changes within the AWS environment.\nFalco was created by Sysdig in 2016. It was the first runtime security project to join CNCF as a sandbox-level project, and has since graduated to incubation status.\nA set of out-of-the-box Falco rules for CloudTrail is packaged with the Sysdig CloudConnector allowing you to easily generate detections and alerts on abnormal behavior changes. The included out-of-the-box CloudTrail rules can detect events like:\n Add an AWS user to a group. Allocate a New Elastic IP Address to AWS Account. Attach an Administrator Policy. Create an AWS user. Deactivate MFA for user access. Delete bucket encryption.  You can also complement these with your own custom rules.\nThe Falco rules are also mapped against NIST 800-190 compliance standard controls. More compliance mapping for additional compliance standards like PCI or CIS will be provided in the future\nUsing Falco to detect and alert on AWS configuration changes is similar to runtime detections of your application stack. This makes Sysdig Secure your central location to detect and alert on all aspects of your security posture.\n"
},
{
	"uri": "//localhost:1313/10_prerequisites.html",
	"title": "Prerequisites",
	"tags": [],
	"description": "",
	"content": " Workshop Prerequisites There are a few prerequisite tasks you must perform before getting started on this workshop. These are:\n Access an AWS account Launch Cloud9 IDE Workspace Sign-up for a Sysdig Trial account  We will step through each of these in turn.\n"
},
{
	"uri": "//localhost:1313/10_prerequisites/12_start_workshop.html",
	"title": "1. Access AWS Account...",
	"tags": [],
	"description": "",
	"content": " Access an AWS account To start the workshop, follow one of the following depending on whether you are\u0026hellip;\n Attending an AWS hosted event, or Running the workshop on your own  Both options are explained below.\nOnce you have completed with either setup, continue with Launch a Cloud9 IDE Workspace\nAttending an AWS hosted event To complete this workshop, you are provided with an AWS account via the AWS Event Engine service. A team hash will be provided to you by event staff.\nIf you are currently logged in to an AWS Account, you can logout using this link\n Create AWS Account 1 . Connect to the portal by clicking the button or browsing to https://dashboard.eventengine.run/. The following screen shows up. Enter the provided hash in the text box. The button on the bottom right corner changes to Accept Terms \u0026amp; Login. Click on that button to continue.\nLeave the Event Engine tab open (A new tab will be used for the next step)\n 2 . Choose AWS Console, then Open AWS Console.\n3 . Use a single region for the duration of this workshop. This workshop supports the following regions:\n us-east-1 (US East - N.Virginia)  Please select US East (N.Virginia) in the top right corner.\nThis account will expire at the end of the workshop and the all the resources created will be automatically deprovision-ed. You will not be able to access this account after today.\n Running the workshop on your own Only complete this section if you are running the workshop on your own. If you are at an AWS hosted event (such as re:Invent, Kubecon, Immersion Day, etc), go to Start the workshop at an AWS event.\n  Your account must have the ability to create new IAM roles and scope other IAM permissions.\n You are responsible for the cost of the AWS services used while running this workshop in your AWS account.\n  If you don\u0026rsquo;t already have an AWS account with Administrator access: create one now by clicking here\n Once you have an AWS account, ensure you are following the remaining workshop steps as an IAM user with administrator access to the AWS account: Create a new IAM user to use for the workshop\n Enter the user details:  Attach the AdministratorAccess IAM Policy:  Click to create the new user:  Take note of the login URL and save:   "
},
{
	"uri": "//localhost:1313/10_prerequisites/16_start_cloud9workspace.html",
	"title": "2. Launch Cloud9 IDE Workspace",
	"tags": [],
	"description": "",
	"content": " AWS Cloud9 is a cloud-based integrated development environment (IDE) that Let’s you write, run, and debug your code with just a browser. It includes a code editor, debugger, and terminal. Cloud9 comes prepackaged with essential tools for popular programming languages, including JavaScript, Python, PHP, and more, so you don’t need to install files or configure your laptop for this workshop.\nWe will use Amazon Cloud9 to access our AWS account via the AWS CLI in this Workshop. There are a few steps to complete to set this up\n Create a new Cloud9 IDE environment Create an IAM role for your workspace Attach the IAM role to your workspace Configure workshop specific requirements  Create a new Cloud9 IDE environment 1 . Within the AWS console, use the region drop list to select us-east-1 (N. Virginia). This will ensure the workshop script provisions the resources in this same region..\n2 . Navigate to the cloud9 console or just search for it under the AWS console services menu.\n3 . Click the Create environment button\n4 . For the name use sysdig-workshop, then click Next step\n5 . Select the default instance type t3.medium\n6 . Leave all the other settings as default and click Next step followed by Create environment\nThis will take about 1-2 minutes to provision\n Configure Cloud9 IDE environment When the environment comes up, customize the environment by:\n1 . Close the welcome page tab\n2 . Close the lower work area tab\n3 . Open a new terminal tab in the main work area.\n4 . Hide the left hand environment explorer by clicking on the left side environment tab.\nIf you don\u0026rsquo;t like this dark theme, you can change it from the View / Themes Cloud9 workspace menu.\n Cloud9 requires third-party-cookies. You can whitelist the specific domains. You are having issues with this, Ad blockers, javascript disablers, and tracking blockers should be disabled for the cloud9 domain, or connecting to the workspace might be impacted.\n Create an IAM role for your workspace Starting from here, when you see command to be entered such as below, you will enter these commands into Cloud9 IDE. You can use the Copy to clipboard feature (right hand upper corner) to simply copy and paste into Cloud9. In order to paste, you can use Ctrl + V for Windows or Command + V for Mac.\n  Follow this deep link to create an IAM role with Administrator access. Confirm that AWS service and EC2 are selected, then click Next: Permissions to view permissions. Confirm that AdministratorAccess is checked, then click Next: Tags, then Next: Review to review. Enter Sysdig-Workshop-Admin for the Role name, and select Create role   Attach the IAM role to your Workspace  Follow this deep link to find your Cloud9 EC2 instance\n Select the instance, then choose Actions / Security / Modify IAM role\n Choose Sysdig-Workshop-Admin from the IAM Role drop down, and select Save\n  Configure workspace for Sysdig Workshop Cloud9 normally manages IAM credentials dynamically. This isn\u0026rsquo;t currently compatible with the EKS IAM authentication, so we will disable it and rely on the IAM role instead.\n  Return to your workspace and click the gear icon (in top right corner), or click to open a new tab and choose \u0026ldquo;Open Preferences\u0026rdquo;\n Select AWS SETTINGS and turn off AWS managed temporary credentials\n Close the Preferences tab\n Copy and run (paste with Ctrl+P) the commands below.\nBefore running it, review what it does by reading through the comments.\n# Update awscli sudo pip install --upgrade awscli \u0026amp;\u0026amp; hash -r # Install jq command-line tool for parsing JSON, and bash-completion sudo yum -y install jq gettext bash-completion moreutils # Install yq for yaml processing echo \u0026#39;yq() { docker run --rm -i -v \u0026#34;${PWD}\u0026#34;:/workdir mikefarah/yq yq \u0026#34;$@\u0026#34; }\u0026#39; | tee -a ~/.bashrc \u0026amp;\u0026amp; source ~/.bashrc # Verify the binaries are in the path and executable for command in jq aws do which $command \u0026amp;\u0026gt;/dev/null \u0026amp;\u0026amp; echo \u0026#34;$commandin path\u0026#34; || echo \u0026#34;$commandNOT FOUND\u0026#34; done # Remove existing credentials file. rm -vf ${HOME}/.aws/credentials # Set the ACCOUNT_ID and the region to work with our desired region export AWS_REGION=$(curl -s 169.254.169.254/latest/dynamic/instance-identity/document | jq -r \u0026#39;.region\u0026#39;) test -n \u0026#34;$AWS_REGION\u0026#34; \u0026amp;\u0026amp; echo AWS_REGION is \u0026#34;$AWS_REGION\u0026#34; || echo AWS_REGION is not set # Configure .bash_profile export ACCOUNT_ID=$(aws sts get-caller-identity --output text --query Account) echo \u0026#34;export ACCOUNT_ID=${ACCOUNT_ID}\u0026#34; | tee -a ~/.bash_profile echo \u0026#34;export AWS_REGION=${AWS_REGION}\u0026#34; | tee -a ~/.bash_profile aws configure set default.region ${AWS_REGION} aws configure get default.region # Validate that our IAM role is valid. aws sts get-caller-identity --query Arn | grep Sysdig-Workshop-Admin -q \u0026amp;\u0026amp; echo \u0026#34;IAM role valid\u0026#34; || echo \u0026#34;IAM role NOT valid\u0026#34;  If the IAM role is not valid, DO NOT PROCEED. Go back and confirm the steps on this page.\n "
},
{
	"uri": "//localhost:1313/30_module_1.html",
	"title": "1. ECR Automated Image Scanning",
	"tags": [],
	"description": "",
	"content": " Module 1: ECR Automated Image Scanning Overview Amazon Elastic Container Registry (ECR) is a fully-managed Docker container registry that makes it easy for developers to store, manage, and deploy Docker container images. It hosts your container images in a highly available and scalable architecture, allowing you to reliably deploy containers for your applications. Sysdig provides inline scanning of your Amazon ECR registry as part of Sysdig\u0026rsquo;s ImageVision.\nIn this lab we will:\n Setup the Amazon ECR Registry Deploy the Amazon ECR Integration Push and scan an image from the registry See scan results on Sysdig Secure dashboard Download Example Dockerfile and Sources Modify the image and trigger a second scan  Reference Architecture Enabling Amazon ECR Image Scanning is as simple as deploying a single CloudFormation template, and once deployed, all images that are pushed to the registry will be automatically scanned within your AWS account.\nHow this is implemented is illustrated below.\nOnce a new image is pushed to Amazon ECR, this is picked up by Amazon EventBridge and passed to a Lambda function which creates an ephemeral CodeBuild task to build and scan the base image. The results of the scan are then sent to the Sysdig Secure backend. You are not required to configure, or expose, the registry on the Sysdig Secure side. Also, the image itself is not sent to Sysdig, but only the image metadata.\nAn important point to note is that, although the scan actually happens with this AWS pipeline, you maintain the scanning policies and view results within Sysdig.\nAbout AWS CodeBuild AWS CodeBuild is a fully managed continuous integration service. CodeBuild compiles source code, runs tests, and produces deployable software packages without the need to provision, manage, and scale your own build servers.\n"
},
{
	"uri": "//localhost:1313/10_prerequisites/30_sysdig.html",
	"title": "3. Sign-up for a Sysdig Trial account",
	"tags": [],
	"description": "",
	"content": "You need a Sysdig Secure account to complete this workshop. In particular you will need to make a note of your account\u0026rsquo;s associated API token \u0026amp; API Endpoint to configure the integrations.\n Sign-up for a free Sysdig trial here https://sysdig.com/company/free-trial/. Remember to select Sysdig Secure under the Trial Offer\u0026hellip; dropdown.\n You will receive a confirmation email with a confirmation link  Click the link and log into Sysdig, and make a note of the following two items (see animated GIF below for details on how to obtain these two values)\n The \u0026lsquo;Sysdig Secure API Endpoint\u0026rsquo; you are routed to. This will be the Sysdig Secure hostname in the browser URL. It should be one of the following\n https://secure.sysdig.com https://eu1.app.sysdig.com https://us2.app.sysdig.com  Make sure you do not leave a trailing / in this URL. For more information of Sysdig\u0026rsquo;s regional URLs, please refer to the Sysdig documentation.\n Your \u0026lsquo;Sysdig Secure API Token\u0026rsquo;. Click your initials on the left nav bar, click \u0026lsquo;Settings\u0026rsquo; and navigate to \u0026lsquo;User Profile\u0026rsquo;.\nIMPORTANT: Make sure you DO NOT use the Sysdig Monitor API Token, or the Access Token!\n   "
},
{
	"uri": "//localhost:1313/30_module_1/30_setup_ecr.html",
	"title": "Setup Amazon ECR Registry",
	"tags": [],
	"description": "",
	"content": " For the purposes of this lab you need to create an Amazon ECR registry. To do this, follow the steps below\n Log into your Cloud9 Workspace\n Run the following command to create a repository. The name is arbitrary, but for continuity in the lab please use aws-workshop\naws ecr create-repository --repository-name aws-workshop --image-scanning-configuration scanOnPush=true The output will be as follows\n{ \u0026#34;repository\u0026#34;: { \u0026#34;repositoryArn\u0026#34;: \u0026#34;arn:aws:ecr:us-east-1:845151661675:repository/aws-workshop\u0026#34;, \u0026#34;registryId\u0026#34;: \u0026#34;845151661675\u0026#34;, \u0026#34;repositoryName\u0026#34;: \u0026#34;aws-workshop\u0026#34;, \u0026#34;repositoryUri\u0026#34;: \u0026#34;845151661675.dkr.ecr.us-east-1.amazonaws.com/aws-workshop\u0026#34;, \u0026#34;createdAt\u0026#34;: 1602848100.0, \u0026#34;imageTagMutability\u0026#34;: \u0026#34;MUTABLE\u0026#34;, \u0026#34;imageScanningConfiguration\u0026#34;: { \u0026#34;scanOnPush\u0026#34;: true }, \u0026#34;encryptionConfiguration\u0026#34;: { \u0026#34;encryptionType\u0026#34;: \u0026#34;AES256\u0026#34; } } } You can view the repository in Amazon UI\n  Authenticate AWS CLI With Amazon ECR registry Shortly you will use your Cloud9 Workspace to create and push a docker container to your new ECR Repository, however, before doing so you must configure docker\u0026rsquo;s access to the repository.\n Log into your Cloud9 workspace\n Authenticate the Docker command line tool to this Amazon ECR registry, using AWS CLI tool as follows\nexport ECR_NAME=aws-workshop export REGION=us-east-1 export AWS_ACCOUNT=$(aws sts get-caller-identity | jq \u0026#39;.Account\u0026#39; | xargs) echo \u0026#34;$ECR_NAME, $REGION, $AWS_ACCOUNT\u0026#34; aws ecr get-login-password --region $REGION | \\ docker login --username AWS --password-stdin \\ $AWS_ACCOUNT.dkr.ecr.$REGION.amazonaws.com The output should look similar to the following\nWARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json. Configure a credential helper to remove this warning. See https://docs.docker.com/engine/reference/commandline/login/#credentials-store Login Succeeded  Note For more details on this procedure, please refer to Amazon ECR registries - Amazon ECR\n"
},
{
	"uri": "//localhost:1313/30_module_1/31_deploy_ecr_integration.html",
	"title": "Deploy the Amazon ECR Integration",
	"tags": [],
	"description": "",
	"content": "This integration enables the Amazon Elastic Container Registry (ECR) to automatically trigger an action to scan every new container that is pushed into the registry.\n Log into your AWS Console and select \u0026lsquo;US East (N. Virginia) us-east-1\u0026rsquo; from the \u0026lsquo;Select a Region\u0026rsquo; dropdown on the top right.\nFor the purposes of this exercise we will be using AWS Region us-east-1\n Navigate to this CloudFormation template.  Click Next.  There are three items to update on this screen:\n For \u0026lsquo;ScanningType\u0026rsquo; make sure the default value of \u0026lsquo;Inline\u0026rsquo; is selected\n For \u0026lsquo;SysdigSecureEndpoint\u0026rsquo;, enter the value in your Sysdig Secure domain name, i.e. one of the following\n secure.sysdig.com eu1.app.sysdig.com us2.app.sysdig.com  For \u0026lsquo;SysdigSecureAPIToken\u0026rsquo;, enter your \u0026lsquo;Sysdig Secure API Token\u0026rsquo; for the Sysdig Secure account you created earlier. You can find in your Sysdig Secure User Profile (Note Please make sure you logged into Sysdig Secure, and not Sysdig Monitor).   Click \u0026lsquo;Next\u0026rsquo;. You will be presented with \u0026lsquo;Configure stack options\u0026rsquo; page.\n Click \u0026lsquo;Next\u0026rsquo; accepting the default configuration options.  Make sure you tick the box acknowledging that AWS CloudFormation might create IAM resources with custom names.\n Click \u0026lsquo;Create stack\u0026rsquo;.\nYou can view the status of the deployment from the Amazon CloudFormation screen.   This deployment will create a new Amazon CloudBuild project that will automatically scan container images pushed to ECR registries.\nTo view your Amazon CloudBuild projects, browse to Developer Tools \u0026gt; CodeBuild "
},
{
	"uri": "//localhost:1313/30_module_1/32_image_from_registry.html",
	"title": "Push and Scan an Image from the Registry",
	"tags": [],
	"description": "",
	"content": " Download Example Dockerfile and Sources Now that our automated scanner is in place, we can test it by pushing a Docker container, and check if it scans.\nTo illustrate the images scanning we will build an example Node.JS application based on the official “hello world” example described in their website.\n Go to your Cloud9 Workspace and download and uncompress example container files\nwget https://github.com/sysdiglabs/hello-world-node-vulnerable/releases/download/v1.0/hello-world-node-vulnerable.zip unzip hello-world-node-vulnerable.zip cd hello-world-node-vulnerable/ And build and push the image to ECR\nexport IMAGE=$AWS_ACCOUNT.dkr.ecr.$REGION.amazonaws.com/$ECR_NAME docker build . -t $IMAGE docker push $IMAGE As soon as the image has been pushed to the registry, a new Amazon CodeBuild pipeline will be automatically created that executes an image scan using the integrated Sysdig Inline Scanner.\nIf you wish, you can check the CodeBuild pipeline status by visiting: Developer Tools \u0026gt; CodeBuild If you wish, you can drill down to tail the logs as the scan proceeds\n  Once complete the scan will show the status \u0026lsquo;Failed\u0026rsquo;. Important This may mean the image has failed the scan, and not that the image scan process itself has failed. Check the CodeBuild pipeline logs to verify.\nOptional: Further Information You can see a complete log of the scan process by clicking ECS Scan log. This shows\n layers of the image getting pulled and flattened (lines 24-199)\n analysis phase, the metadata getting sent to (lines 201-204)\n metadata getting posted to Sysdig Backend (line 206)\n backend analyses the metadata between lines 206 \u0026amp; 207  results of the scan are returned from the Sysdig Backend (lines 207-1979)\n inline scanner script returns exit code 1 (line 1985)\n  See Scan Results on Sysdig Secure Dashboard To see the scan results on Sysdig Secure Dashboard,\n Log into the Sysdig Secure UI, and browse to \u0026lsquo;Image Scanning \u0026gt; Scan Results\u0026rsquo;.   Click your new aws-workshop image.\nYou\u0026rsquo;ll see the image have several major vulnerabilities.\n  With Sysdig Secure you have full visibility of the security and compliance posture across your entire estate, in a single pane of glass, and as a central location for all security profiles and policies.\n"
},
{
	"uri": "//localhost:1313/30_module_1/33_image_rescan.html",
	"title": "Modify the image and trigger a second scan",
	"tags": [],
	"description": "",
	"content": "For illustration purposes, let\u0026rsquo;s rebuild our image and make it more secure by starting with a different Base image.\n Go back into Cloud9 Workspace\n As a bit of housekeeping, first lets delete the older node image as follows to free up space on our Cloud9 workspace,\ndocker rmi node:12 Edit the Dockerfile and in the first line update the base image from\nFROM node:12 to\nFROM bitnami/node:12 The file should look like this\nFROM bitnami/node:12 # Create app directory WORKDIR /usr/src/app # Install app dependencies # A wildcard is used to ensure both package.json AND package-lock.json are copied # where available (npm@5+) COPY package*.json ./ RUN npm install # If you are building your code for production # RUN npm ci --only=production # Bundle app source COPY . . EXPOSE 8080 CMD [ \u0026#34;node\u0026#34;, \u0026#34;server.js\u0026#34; ] Now rebuild and push the image again with:\ndocker build . -t $IMAGE docker push $IMAGE The image will automatically be scanned, as before.\n Once completed, you will see that the scan result now shows a more recent image (based on debian/10) with fewer vulnerabilities.   "
},
{
	"uri": "//localhost:1313/30_module_1/34_review.html",
	"title": "Module Review",
	"tags": [],
	"description": "",
	"content": "In this module we saw how to use Sysdig\u0026rsquo;s AWS ECR integration to automatically scan images upon being added to Amazon ECR.\nIn particular we looked at how to deploy the Amazon ECR Integration using AWS CloudFormation template. Then we saw how to setup the Amazon ECR Registry and push images to the it and observe them being scanned.\nFinally we looked at how to view the scan results on the Sysdig Secure dashboard.\nIn the next module we will look at how to scan images automatically in AWS ECS and Fargate.\n"
},
{
	"uri": "//localhost:1313/30_module_1/35_cleanup.html",
	"title": "Cleanup",
	"tags": [],
	"description": "",
	"content": " Remove container image from Amazon ECR Registry\ndocker system prune --all Remove Docker Node.JS Dockerfile \u0026amp; Source\nrm -rf /home/ec2-user/environment/hello-world-node-vulnerable rm -rf /home/ec2-user/environment/hello-world-node-vulnerable.zip  Remove Amazon ECR Registry\naws ecr delete-repository --repository-name aws-workshop --force Remove Amazon ECR Integration\naws cloudformation delete-stack --stack-name ECSImageScanning  "
},
{
	"uri": "//localhost:1313/40_module_2.html",
	"title": "2. Fargate &amp; ECS Automated Image Scanning",
	"tags": [],
	"description": "",
	"content": " Module 2: Fargate \u0026amp; ECS Automated Image Scanning Module Overview Amazon Fargate is a serverless compute engine for containers that works with both Amazon Elastic Container Service (ECS) and Amazon Elastic Kubernetes Service (EKS). It allocates the correct amount of compute resources, eliminating the need to choose instance types and scaling cluster capacity. With Fargate, you pay for the minimum resources required to run your containers. Sysdig provides the ability to scan running Fargate services for known issues, in a similar manner to how it scans Amazon ECR.\nIn this lab we will\n Install Amazon ECS CLI Deploy Sysdig Secure automated image scanner for Fargate Deploy an ECS cluster using Fargate See that CodeBuild pipelines are automatically created to scan them See scan results on Sysdig Secure dashboard  Reference Architecture Any deploy command directed at ECS Fargate will trigger an image scanning event. In particular the deploy command is detected by Amazon EventBridge, which will trigger a CodeBuild pipeline via an AWS Lambda function. It is within this CodeBuild pipeline that the image scanning runs. This is very similar workflow to how we seen earlier with Amazon ECR scanning.\nThe Sysdig inline image scanner will inspect the image to be deployed and will send its metadata to the Sysdig backend. The actual image contents won\u0026rsquo;t leave the CodeBuild pipeline.\nThe Sysdig backend then evaluates the container metadata against your security policies. It will generate a scan report if the image doesn\u0026rsquo;t pass your security requirements, so you can take action.\n"
},
{
	"uri": "//localhost:1313/40_module_2/40_install_amazon_ecs_cli.html",
	"title": "Install Amazon ECS CLI",
	"tags": [],
	"description": "",
	"content": "We will use the Amazon ECS CLI tool to deploy an example ECS cluster, so we\u0026rsquo;ll need to install it on our Cloud9 Workspace. To install Amazon ECS CLI, follow the steps below\n Log into your Cloud9 Workspace\n Download the Amazon ECS CLI binary and make it executable .\nsudo curl -sLo /usr/local/bin/ecs-cli https://amazon-ecs-cli.s3.amazonaws.com/ecs-cli-linux-amd64-latest sudo chmod +x /usr/local/bin/ecs-cli Check installation\necs-cli --version Now create a file named task-execution-assume-role.json for our IAM role as follows\ncat \u0026lt;\u0026lt;- \u0026#39;EOF\u0026#39; \u0026gt; \u0026#34;task-execution-assume-role.json\u0026#34; { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;ecs-tasks.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34; } ] } EOF Create task execution role and attach the task execution role policy:\naws iam --region us-east-1 create-role --role-name ecsTaskExecutionRole --assume-role-policy-document file://task-execution-assume-role.json aws iam --region us-east-1 attach-role-policy --role-name ecsTaskExecutionRole --policy-arn arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy  "
},
{
	"uri": "//localhost:1313/40_module_2/41_deploy_image_scanner_for_fargate.html",
	"title": "Deploy Sysdig Secure Automated Image Scanner for Fargate",
	"tags": [],
	"description": "",
	"content": "To deploy the Sysdig image scanner for Fargate, we\u0026rsquo;ll again use Amazon CloudFormation. The procedure is identical to how we installed Amazon ECR Integration in the previous lab, so this time we\u0026rsquo;ll use the AWS CLI instead.\nNote You can find instructions on using the CLI on the Sysdig Fargate scanning installation page\n Configure your Secure API Token and Secure API Endpoint as environment variables.\nSecureAPIToken\u2029=\u0026lt;YOUR_API_TOKEN\u0026gt;SecureEndpoint=\u0026lt;YOUR_API_ENDPOINT\u0026gt; You should have made a note of these environment variables when setting up your Cloud9 Workspace.\nMake sure your Sysdig SecureAPIToken and SecureEndpoint environment variables are set correctly.\necho $SecureAPIToken echo $SecureEndpoint Let\u0026rsquo;s set our CloudFormation template URL as an environment variable to simplify the actual aws command.\nCFURI=\u0026#34;https://cf-templates-secure-scanning-ecs.s3.amazonaws.com/ecs-image-scanning.template\u0026#34; Then run the the following AWS CloudFormation command (which uses those environment parameters)\naws cloudformation create-stack \\ --stack-name ECSImageScanning \\ --template-body $CFURI \\ --parameters ParameterKey=ECSInlineSecureAPIToken,ParameterValue=$SecureAPIToken ParameterKey=ECSInlineSecureEndpoint,ParameterValue=$SecureEndpoint ParameterKey=ECSInlineScanningType,ParameterValue=Inline \\ --capabilities \u0026#34;CAPABILITY_NAMED_IAM\u0026#34;  You can check the status of the CloudFormation task by browsing to the CloudFormation UI\nWait until the CloudFormation task completes, which may take several minutes.\nOnce all stacks are created, you will be ready to deploy our ECS tasks in a Fargate cluster securely, as all images will be scanned automatically. In the next steps we will see this scanning as it happens.\n"
},
{
	"uri": "//localhost:1313/40_module_2/42_deploy_an_ecs_cluster.html",
	"title": "Deploy an ECS cluster using Fargate",
	"tags": [],
	"description": "",
	"content": "To illustrate automated scanning, we will now deploy a sample ECS cluster that scales using Fargate. For the purposes of the lab this will consist of this sample PHP appliction running in a Docker Compose environment - https://hub.docker.com/r/amazon/amazon-ecs-sample.\n Create a cluster configuration and create a cluster\necs-cli configure --cluster tutorial --default-launch-type FARGATE --config-name tutorial --region us-east-1 ecs-cli up --cluster-config tutorial --ecs-profile tutorial-profile The output should show a VPC and two Subnets have been created:-\nINFO[0000] Created cluster cluster=tutorial region=us-east-1 INFO[0000] Waiting for your cluster resources to be created... INFO[0000] Cloudformation stack status stackStatus=CREATE_IN_PROGRESS INFO[0060] Cloudformation stack status stackStatus=CREATE_IN_PROGRESS VPC created: vpc-046ed77edcd796e19 Subnet created: subnet-045df8f58a51b2291 Subnet created: subnet-0e4623283c4907ea7 Cluster creation succeeded. We will use a bash script to create our ECS cluster. So first lets instantiate the script by copying and pasting the following commands\ncd /home/ec2-user/environment curl -s https://gist.githubusercontent.com/johnfitzpatrick/d55097212d9bb4e1442383a5e3339b01/raw/272b0f1a45fa8a54571ebb707b7e7d51e4db0fb5/deploy-amazon-ecs-sample.sh \u0026gt; deploy-amazon-ecs-sample.sh chmod +x deploy-amazon-ecs-sample.sh Now run the script deploy-amazon-ecs-sample.sh, copying and pasting the VPC \u0026amp; Subnet values from the above out when prompted\n./deploy-amazon-ecs-sample.sh Note You can subsequently get the VPC and Subnet details requested from the CloudFormation UI\nThis script will\n Retrieve the id of the default security group for the VPC created, and allows inbound access on port 80\n Create a ecs-params.yml file using the subnets and security group already retrieved. This file should look as follows\nversion: 1 task_definition: task_execution_role: ecsTaskExecutionRole ecs_network_mode: awsvpc task_size: mem_limit: 0.5GB cpu_limit: 256 run_params: network_configuration: awsvpc_configuration: subnets: - \u0026#34;subnet-045df8f58a51b2291\u0026#34; - \u0026#34;subnet-0e4623283c4907ea7\u0026#34; security_groups: - \u0026#34;sg-3a1f94b6\u0026#34; assign_public_ip: ENABLED Create a docker-compose.yaml to instantiate the image amazon/amazon-ecs-sample. This file looks as follows\nversion: \u0026#39;3\u0026#39; services: web: image: amazon/amazon-ecs-sample ports: - \u0026#34;80:80\u0026#34; logging: driver: awslogs options: awslogs-group: tutorial awslogs-region: us-east-1 awslogs-stream-prefix: web Optionally, for details of this script you can run the following command\ncat ./deploy-amazon-ecs-sample.sh  Once the script has completed you can see details of of the ECS cluster on the Amazon ECS UI\n  "
},
{
	"uri": "//localhost:1313/40_module_2/43_initiate_scan.html",
	"title": "Initiate CodeBuild Pipelines Build and Scan",
	"tags": [],
	"description": "",
	"content": "Now that a sample image has been deployed, the scanner should pick this up and scan it automatically\n Now go to CodeBuild \u0026gt; Build projects and see the task progress.\n Click on \u0026lsquo;Failed\u0026rsquo; next to ECSInlineSecureScanning to drill down on it.\n Click \u0026lsquo;Failed\u0026rsquo; link and scroll down to see the scan details\n  "
},
{
	"uri": "//localhost:1313/40_module_2/44_sysdig_secure_dashboard.html",
	"title": "View Results on Sysdig Secure Dashboard",
	"tags": [],
	"description": "",
	"content": "The beauty of the Amazon ECS Fargate with Sysdig is that you have a centralised location to report on your scanning results.\n Log into Sysdig Secure, and Browse to \u0026lsquo;Image Scanning \u0026gt; Scan Results\u0026rsquo;.\n You can drill into amazon/amazon-ecs-sample to see details results of the scan\n  "
},
{
	"uri": "//localhost:1313/40_module_2/45_review.html",
	"title": "Module Review",
	"tags": [],
	"description": "",
	"content": "In this module we saw how to use Sysdig\u0026rsquo;s AWS ECS/Fargate integration to automatically scan deployed images.\nWe first deployed Sysdig\u0026rsquo;s AWS ECS/Fargate integration using a CloudFormation template.\nIn particular we looked at how to deploy the Amazon ECR Integration. Then we deployed an ECS cluster using Fargate and watched as CodeBuild pipelines are automatically created to scan the images.\nFinally we saw how to view the scan results on the Sysdig Secure dashboard.\nIn the next module we will look at how Sysdig CloudConnector uses AWS CloudTrail along with Falco to provide runtime protection.\n"
},
{
	"uri": "//localhost:1313/40_module_2/46_cleanup.html",
	"title": "Cleanup",
	"tags": [],
	"description": "",
	"content": " Remove ecsTaskExecutionRole\naws iam detach-role-policy --role-name ecsTaskExecutionRole --policy-arn arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy --region us-east-1 aws iam --region us-east-1 delete-role --role-name ecsTaskExecutionRole Remove ECS Cluster\nstack=tutorial services=\u0026#34;$(aws ecs list-services --cluster \u0026#34;$stack\u0026#34; | grep \u0026#34;$stack\u0026#34; | sed -e \u0026#39;s/\u0026#34;//g\u0026#39; -e \u0026#39;s/,//\u0026#39;)\u0026#34; for service in $services; do aws ecs update-service --cluster \u0026#34;$stack\u0026#34; --service \u0026#34;$service\u0026#34; --desired-count 0 aws ecs delete-service --cluster \u0026#34;$stack\u0026#34; --service \u0026#34;$service\u0026#34; done for id in $(aws ecs list-container-instances --cluster \u0026#34;$stack\u0026#34; | grep container-instance | sed -e \u0026#39;s/\u0026#34;//g\u0026#39; -e \u0026#39;s/,//\u0026#39;); do aws ecs deregister-container-instance --cluster \u0026#34;$stack\u0026#34; --container-instance \u0026#34;$id\u0026#34; --force done for service in $services; do aws ecs wait services-inactive --cluster \u0026#34;$stack\u0026#34; --services \u0026#34;$service\u0026#34; done aws ecs delete-cluster --cluster \u0026#34;$stack\u0026#34; aws cloudformation delete-stack --stack-name \u0026#34;$stack\u0026#34; Delete log group created with ecs-cli compose\naws logs delete-log-group --log-group-name tutorial Remove Image Scanner Integration for Fargate\naws cloudformation delete-stack --stack-name ECSImageScanning aws cloudformation delete-stack --stack-name amazon-ecs-cli-setup-tutorial  "
},
{
	"uri": "//localhost:1313/50_module_3.html",
	"title": "3. CloudTrail Runtime Security",
	"tags": [],
	"description": "",
	"content": " Module 3: CloudTrail Runtime Security Module Overview Every action taken over your infrastructure resources results in a registry in AWS CloudTrail. This includes all AWS account activity, actions taken through the AWS Management Console, AWS SDKs, command line tools, and other AWS services. This event history is extremely useful for detecting unwanted or unexpected activity involving your AWS resources, however it\u0026rsquo;s quite noisy, and being JSON, it\u0026rsquo;s not really human readable so can be hard to understand.\nAlso, as your infrastructure grows and the number of AWS services are released, the amount of events and operational trails can become so huge that analyzing them is no longer practical.\nIn this module we will explain how to audit AWS CloudTrail events with Sysdig CloudConnector. Once deployed in your infrastructure, the Sysdig CloudConnector analyzes every CloudTrail entry in real time, and provides AWS threat detection by evaluating each event against a flexible set of security rules based on Falco. This allows you to detect threats and raise notifications so you can address security threats as quickly as possible.\nReference Architecture Similar to ECS Fargate serverless, incoming CloudTrail events are fetched and stored in an S3 bucket. A subscription in the SNS topic will then forward the events to the Sysdig CloudConnector endpoint. The CloudConnector will then analyze each event against a configured set of Falco rules.\nSysdig CloudConnector provides several notification options, including sending security findings to Sysdig Backend, as well as AWS Security Hub and AWS CloudWatch, so you can review the security events without leaving your AWS console.\nAn important to note is Sysdig remains your single reference point for all infrastructure \u0026amp; runtime security configuration as well as associated events and alerts.\n"
},
{
	"uri": "//localhost:1313/50_module_3/51_setup_cloudtrail_runtime_security.html",
	"title": "Setup CloudTrail Runtime Security",
	"tags": [],
	"description": "",
	"content": " There are two steps required to enable CloudTrail runtime security:\n Firstly, you must enable AWS Security Hub in the account, then Deploy the Sysdig CloudConnector CloudFormation template.  If you prefer learning by watching over reading, you can find an animated image at the bottom with all the steps listed below.\n Step 1. Enable AWS Security Hub To enable AWS Security Hub:\n Log into your Cloud9 Workspace\n Run the following command (no output will be generated)\naws securityhub enable-security-hub --enable-default-standards Log into your AWS account and browse to the AWS Security Hub.\nIf you see the Summary web page, it means its enabled in your account. You can skip to the Step2 below.\n  You may see a temporary red warning about AWS Config not being appropriately enabled, but it will disappear on its own once the Security Hub detects that the activation has been made. It has no relation to the use of Sysdig CloudConnector.\n Then, click '**Enable Security Hub**'. After this, the _\"Summary\"_ page for Security Hub will be shown. In the \u0026ldquo;Welcome to AWS Security Hub\u0026rdquo; page, you can indicate which security standard controls you want to enable, or accept the default. These controls are part of the default AWS Security Hub mechanism, and they are not related to the detections that Sysdig CloudConnector is going to find for you.\n -- Step 2. Install the CloudConnector Follow the steps below to install the Sysdig CloudConnector using a CloudFormation Template:\n Navigate to the CloudFormation template for Sysdig CloudConnector deployment. The template will preview in CloudFormation.  On the “Create stack” section, click the \u0026lsquo;Next\u0026rsquo; button to start setting up the template.  The “Specify stack details” section has no parameters for you to configure, so you can just press the Next button.  On “Configure stack options” screen, press the Next button.\nYou can optionally add tag keys and values to the deployment, but no further configuration is required.\n You will be presented with a summary of all the parameters you previously introduced. Please note that dedicated IAM roles will be created to perform the scanning. These roles follow the \u0026ldquo;least privilege principle\u0026rdquo; to enforce maximum security.\n Finally click the checkbox\n Then press the Create stack button\n  All ready! On the CloudFormation dashboard, you should see the template status is \u0026lsquo;CREATE_IN_PROGRESS\u0026rsquo;.\nThe creation process may take up to ten minutes. It will show as “CREATE_COMPLETE” once the deployment has completed successfully.\nStep summary "
},
{
	"uri": "//localhost:1313/50_module_3/53_detecting_runtime_cloud_security_threats.html",
	"title": "Detecting Runtime Cloud Security Threats",
	"tags": [],
	"description": "",
	"content": "Let\u0026rsquo;s look at an example of AWS threat detection in action with CloudTrail and the Sysdig CloudConnector. To do so we\u0026rsquo;ll create an S3 bucket, and make it public\n Log into Cloud9 Workspace\nS3 bucket names are globally unique, so use your initials in lower case combined with a timestamp\n First set your initials as an environment variable\nINITIALS=\u0026lt;your initials\u0026gt; Now create the S3 bucket, ensuring the bucket name is in lowercase.\nBUCKETNAME=\u0026#34;${INITIALS,,}\u0026#34;-$(date +%s) aws s3api create-bucket --bucket $BUCKETNAME --acl public-read Now delete the S3 bucket\u0026rsquo;s encryption. This should be considered a potential security threat.\naws s3api delete-bucket-encryption --bucket $BUCKETNAME To view details of this event, browse to CloudTrail then \u0026lsquo;Event History\u0026rsquo;\nIf you scroll down you\u0026rsquo;ll see details of the new CloudTrail event in JSON format:\n Below is an example of a \u0026lsquo;DeleteBucketEncryption\u0026rsquo; event raised after our previous command\n  It can take several minutes for new events to appear in CloudTrail. In the meantime you can browse the existing events created earlier from earlier activity in the account.\n ![insertexamplejson]\nPlease note that all data in the JSON doc above is fictitious and is used as an example.\n All CloudTrail events have the following key fields:\n userIdentity: The user who sent the request. eventName: Specifies the type of event. requestParameters: Contains all of the parameters related to the request.  If a request has an errorCode field, it means that it could not be processed because of an error. For example, the requester may not have had permission to perform a change.\nIn this case, we can see how a policy has just been attached (AttachUserPolicy) to a user (admin_test) with administrator access (arn:aws:iam::aws:policy/AdministratorAccess).\nA Falco rule to detect this elevation of privileges would look like this:\n- rule: Delete bucket encryption desc: Detect deleting configuration to use encryption for bucket storage condition: \u0026gt; jevt.value[/eventName]=\u0026#34;DeleteBucketEncryption\u0026#34; and not jevt.value[/errorCode] exists output: \u0026gt; A encryption configuration for a bucket has been deleted (requesting user=%jevt.value[/userIdentity/arn], requesting IP=%jevt.value[/sourceIPAddress], AWS region=%jevt.value[/awsRegion], bucket=%jevt.value[/requestParameters/bucketName]) priority: CRITICAL tags: [cloud, source=cloudtrail, aws, NIST800_53, NIST800_53_AU8] source: k8s_audit Some points to note about this rule:\n The jevt.value contains the JSON content of the event, and we are using it in the condition. Using the jsonpath format, we can indicate what parts of the event we want to evaluate.\n The output will provide context information including the requester username and IP address - this is what will be sent through all of the enabled notification channels.\n  As you can see, this is a regular Falco rule. In fact, this particular rule is already included out-of-the-box in Sysdig CloudConnector. CloudTrail compatibility is achieved by handling its events as JSON objects, and referring to the event information using JSONPath.\n"
},
{
	"uri": "//localhost:1313/50_module_3/54_checking_security_findings_in_the_aws_security_hub.html",
	"title": "Checking Security Findings in AWS Security Hub",
	"tags": [],
	"description": "",
	"content": "You can check these events without leaving the AWS console. This is how findings reported by Sysdig CloudConnector look in the AWS Security Hub:\n Browse to Security Hub and click \u0026lsquo;Findings\u0026rsquo; on the left.   Click on \u0026ldquo;Delete bucket encryption\u0026rdquo; to view all the information you need to take immediate action:   And they appear in JSON format in AWS CloudWatch log streams.\nBrowse to CloudWatch, and click \u0026lsquo;Log groups \u0026gt; cloud-connector \u0026gt; alerts\u0026rsquo;\n  Further, these events can be forwarded to the Sysdig Backend, and alerted upon as necessary in your normal channels.\n"
},
{
	"uri": "//localhost:1313/50_module_3/55_modifying_a_falco_rule_for_cloudtrail.html",
	"title": "Modifying a Falco Rule for CloudTrail",
	"tags": [],
	"description": "",
	"content": "Using Sysdig CloudConnector, you are not limited to the out-of-the-box rules provided. You can modify existing rules, or write your own tailored to your own needs.\nLet’s try first modifying a rule. The following rule checks if a resource is created in a region that you are not usually using. However, to be active you must specify which regions you want to detect.\n- list: disallowed_aws_regions items: [] - rule: AWS command executed on unused region desc: Detect AWS command execution on unused regions condition: \u0026gt; not jevt.value[/errorCode] exists and jevt.value[/awsRegion] in (disallowed_aws_regions) output: \u0026gt; An AWS command has been executed on an unused region (requesting user=%jevt.value[/userIdentity/arn], requesting IP=%jevt.value[/sourceIPAddress], AWS region=%jevt.value[/awsRegion] priority: CRITICAL tags: [cloud, source=cloudtrail, aws] source: k8s_audit  For the disallowed_aws_regions empty list that is included, we are going to extend it to include us-west-1 and us-west-2. Let\u0026rsquo;s update that list to add those regions.\n- list: disallowed_aws_regions items: [us-west-1, us-west-2] append: true When you create custom Falco files, ensure last content in the file is a blank new line without extra tabs to avoid messing with additional files that may be loaded after it.\n To create a disallowed_aws_regions.yaml file in a rules directory, you can run the following\nmkdir -p rules cat \u0026lt;\u0026lt;EOF \u0026gt;rules/disallowed_aws_regions.yaml - list: disallowed_aws_regions items: [us-west-1, us-west-2] append: true EOF When you deploy Cloud Connector, it creates a bucket for you to store configuration and custom Falco code. It\u0026rsquo;s name will be autogenerated with \u0026ldquo;CloudConnector\u0026rdquo; as a prefix. You can work with it using AWS web dashboard, however we are going to explain how to do it using the AWS cli.\n First let\u0026rsquo;s store the bucket name in a variable called cc_bucket\ncc_bucket=$(aws cloudformation list-stack-resources --stack-name CloudConnector --output json | jq \u0026#39;.StackResourceSummaries[] | select(.LogicalResourceId==\u0026#34;CloudConnectorBucket\u0026#34;).PhysicalResourceId\u0026#39; | xargs) echo $cc_bucket Now let\u0026rsquo;s sync our local rules directory with the bucket. Execute this command to upload the directory contents, deleting any extra file located in the remote directory.\naws s3 sync \u0026#34;./rules/\u0026#34; s3://$cc_bucket/rules --delete We now have to restart the Cloud Connector Fargate task to take the new rules into consideration. Again you can do so using the AWS web dashboard, or executing these commands:\ntask_id=$(aws ecs list-tasks --cluster CloudConnector --output json | jq \u0026#39;.taskArns[0]\u0026#39; | /usr/bin/xargs | sed -E \u0026#39;s/.*\\/(.+)/\\1/\u0026#39;) echo $task_id AWS_PAGER=\u0026#34;\u0026#34; aws ecs stop-task --cluster CloudConnector --task $task_id It usually takes the Fargate task a couple of minutes to restart. You can follow Cloud Connector logs to check it\u0026rsquo;s status, discarding very verbose messages that are not essential, using this command:\naws logs tail cloud-connector --follow --filter-pattern \u0026#34;{ $.component != \u0026#34;http-server\u0026#34; \u0026amp;\u0026amp; $.component != \u0026#34;cloudtrail-sns-http-ingestor\u0026#34; }\u0026#34; When you see info level messages indicating the rules have been loaded like the following example, and maybe some alerts, it means the new settings and rules have been loaded.\n Now we create a new log group on us-west-2\n 2020-11-11T17:31:27.770000+00:00 ecs/CloudConnector/6cbd184c9ce446baa1beb5ef2f91fcdb {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;component\u0026#34;:\u0026#34;main\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;2020-11-11T17:31:27Z\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;Starting cloud-connector\u0026#34;} 2020-11-11T17:31:27.770000+00:00 ecs/CloudConnector/6cbd184c9ce446baa1beb5ef2f91fcdb {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;component\u0026#34;:\u0026#34;directory-rule-provider\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;2020-11-11T17:31:27Z\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;loading rules from /rules\u0026#34;} 2020-11-11T17:31:27.959000+00:00 ecs/CloudConnector/6cbd184c9ce446baa1beb5ef2f91fcdb {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;component\u0026#34;:\u0026#34;s3-rule-provider\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;2020-11-11T17:31:27Z\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;loading rules from s3 bucket \u0026#39;cloudconnector-cloudconnectorbucket-6gq5ia7dir18\u0026#39; with path \u0026#39;rules\u0026#39;\u0026#34;} 2020-11-11T17:31:27.973000+00:00 ecs/CloudConnector/6cbd184c9ce446baa1beb5ef2f91fcdb {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;component\u0026#34;:\u0026#34;rule-loader\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;2020-11-11T17:31:27Z\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;loaded 98 rules, 13 lists and 39 macros from 2 rule providers\u0026#34;} 2020-11-11T17:31:28.080000+00:00 ecs/CloudConnector/6cbd184c9ce446baa1beb5ef2f91fcdb {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;component\u0026#34;:\u0026#34;main\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;2020-11-11T17:31:28Z\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;cloud-connector is listening to HTTP requests\u0026#34;} Now that we know the modification has been loaded, we create a new log group on us-west-2 to trigger a a security alert.\naws logs create-log-group --log-group-name \u0026#34;test_unused_region\u0026#34; --region=\u0026#34;us-west-2\u0026#34; CloudTrail takes up to 10 minutes to provide the events. When the event is available, CloudConnector will trigger the rule and we will see a new security event on the log, as well as a new finding appearing in AWS Security Hub.\n 2020-11-11T18:31:07.093000+00:00 ecs/CloudConnector/6b068dbba66a404696db054cf3d46341 {\u0026#34;level\u0026#34;:\u0026#34;warn\u0026#34;,\u0026#34;component\u0026#34;:\u0026#34;console-notifier\u0026#34;,\u0026#34;name\u0026#34;:\u0026#34;AWS Command Executed on Unused Region\u0026#34;,\u0026#34;priority\u0026#34;:\u0026#34;CRITICAL\u0026#34;,\u0026#34;event.ID\u0026#34;:\u0026#34;69cc425f-17db-4647-b27e-8a75d375a40b\u0026#34;,\u0026#34;event.HappenedOn\u0026#34;:\u0026#34;2020-11-11T18:20:36Z\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;2020-11-11T18:31:07Z\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;An AWS command has been executed on an unused region (requesting user=arn:aws:iam::972909301756:root, requesting IP=87.218.230.200, AWS region=us-west-2)\u0026#34;}   "
},
{
	"uri": "//localhost:1313/50_module_3/56_review.html",
	"title": "Module Review",
	"tags": [],
	"description": "",
	"content": "In this module we looked at how to audit AWS CloudTrail events with Sysdig CloudConnector. The Sysdig CloudConnector analyzes every CloudTrail entry in real time, and provides runtime protection using a flexible set of Falco rules, and can forward findings to AWS Security Hub, AWS CloudWatch, as well as to Sysdig Secure.\n"
},
{
	"uri": "//localhost:1313/50_module_3/57_cleanup.html",
	"title": "Cleanup",
	"tags": [],
	"description": "",
	"content": " Delete the log group created to test the Falco rule modification\naws logs delete-log-group --log-group-name \u0026#34;test_unused_region\u0026#34; --region=\u0026#34;us-west-2\u0026#34; Delete an S3 bucket\naws s3api delete-bucket --bucket $BUCKETNAME  "
},
{
	"uri": "//localhost:1313/60_conclusions.html",
	"title": "Conclusions",
	"tags": [],
	"description": "",
	"content": " Conclusions  There are several key points on Sysdig\u0026rsquo;s approach to Amazon ECR and Amazon Fargate image scanning:\n There is no need to build specific pipelines for each image. The scan will be automatically triggered for any workload that is executed in ECS Fargate across your whole infrastructure, or uploaded to ECR.\n As the container metadata is retained in the Sysdig backend, there is no need to re-scan the images. Any update in the vulnerability databases, or any change in your policies, will eventually update the scan reports.\n The Sysdig backend will act as a single source of truth for the security and compliance posture of all your running workloads and container repositories. It centralizes all the security reports and from the same tool, you will also be able to check your compliance status and runtime security events.\n  Keep in mind that this approach is only part of the solution. You can further strengthen your security and compliance by implementing image scanning in other places of your DevOps lifecycle, like the CI/CD pipelines or in the registry. You should also implement other security controls like runtime security, compliance checks, or activity audit. Sysdig helps you extend security controls all over your AWS container services while serving as a single source of truth for the security posture of all your infrastructure.\nAWS security can save your infrastructure from failing at its worst moment. It will protect you and your customer data against misconfigurations, a security compromise, or your wallet from unexpected fees.\nCloudTrail is a great source of truth, as it can see everything that is happening in your AWS accounts. Leverage Sysdig Secure by deploying Sysdig CloudConnector for CloudTrail and obtaining the runtime visibility you need to implement AWS threat detection. Its out-of-the-box set of Falco rules for CloudTrail minimizes the setup effort, response time, and resources needed for investigating security events.\n"
},
{
	"uri": "//localhost:1313/70_cleanup.html",
	"title": "Cleanup",
	"tags": [],
	"description": "",
	"content": " Cleanup Module 3  Delete the log group created to test the Falco rule modification\naws logs delete-log-group --log-group-name \u0026#34;test_unused_region\u0026#34; --region=\u0026#34;us-west-2\u0026#34; Delete an S3 bucket\naws s3api delete-bucket --bucket $BUCKETNAME  Module 2  Remove ecsTaskExecutionRole\naws iam detach-role-policy --role-name ecsTaskExecutionRole --policy-arn arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy --region us-east-1 aws iam --region us-east-1 delete-role --role-name ecsTaskExecutionRole Remove ECS Cluster\nstack=tutorial services=\u0026#34;$(aws ecs list-services --cluster \u0026#34;$stack\u0026#34; | grep \u0026#34;$stack\u0026#34; | sed -e \u0026#39;s/\u0026#34;//g\u0026#39; -e \u0026#39;s/,//\u0026#39;)\u0026#34; for service in $services; do aws ecs update-service --cluster \u0026#34;$stack\u0026#34; --service \u0026#34;$service\u0026#34; --desired-count 0 aws ecs delete-service --cluster \u0026#34;$stack\u0026#34; --service \u0026#34;$service\u0026#34; done for id in $(aws ecs list-container-instances --cluster \u0026#34;$stack\u0026#34; | grep container-instance | sed -e \u0026#39;s/\u0026#34;//g\u0026#39; -e \u0026#39;s/,//\u0026#39;); do aws ecs deregister-container-instance --cluster \u0026#34;$stack\u0026#34; --container-instance \u0026#34;$id\u0026#34; --force done for service in $services; do aws ecs wait services-inactive --cluster \u0026#34;$stack\u0026#34; --services \u0026#34;$service\u0026#34; done aws ecs delete-cluster --cluster \u0026#34;$stack\u0026#34; aws cloudformation delete-stack --stack-name \u0026#34;$stack\u0026#34; Delete log group created with ecs-cli compose\naws logs delete-log-group --log-group-name tutorial Remove Image Scanner Integration for Fargate\naws cloudformation delete-stack --stack-name ECSImageScanning aws cloudformation delete-stack --stack-name amazon-ecs-cli-setup-tutorial  Module 1  Remove container image from Amazon ECR Registry\ndocker system prune --all Remove Docker Node.JS Dockerfile \u0026amp; Source\nrm -rf /home/ec2-user/environment/hello-world-node-vulnerable rm -rf /home/ec2-user/environment/hello-world-node-vulnerable.zip  Remove Amazon ECR Registry\naws ecr delete-repository --repository-name aws-workshop --force Remove Amazon ECR Integration\naws cloudformation delete-stack --stack-name ECSImageScanning  Introduction  Remove S3 Buckets\nCCBUCKET=$(aws s3 ls|grep \u0026#39;cloud-connector\u0026#39; | awk \u0026#39;{print $3}\u0026#39;) aws s3 rm s3://$CCBUCKET --recursive aws s3api delete-bucket --bucket $CCBUCKET CFBUCKET=$(aws s3 ls|grep \u0026#39;cf-templates\u0026#39; | awk \u0026#39;{print $3}\u0026#39;) aws s3 rm s3://$CFBUCKET --recursive aws s3api delete-bucket --bucket $CFBUCKET Remove CloudConnector ECS Cluster\naws ecs delete-cluster --cluster CloudConnector Installing the CloudConnector CloudFormation Template\naws cloudformation delete-stack --stack-name CloudConnector Disable Security Hub\naws securityhub disable-security-hub Delete Sysdig-Workshop-Admin IAM role\n aws iam detach-role-policy --role-name Sysdig-Workshop-Admin --policy-arn arn:aws:iam::aws:policy/AdministratorAccess aws iam delete-role --role-name Sysdig-Workshop-Admin Remove Cloud9 Workstation\n aws cloud9 delete-environment --environment-id $(aws cloud9 list-environments | jq \u0026#39;.environmentIds[]\u0026#39; | xargs)  This action stops the Cloud9 Workspace you are currently working on.\n "
},
{
	"uri": "//localhost:1313/25_prework/241_enable_aws_security_hub.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " If you prefer learning by watching over reading, you can find an animated image at the bottom with all the steps listed below.\n Step 1. Enable AWS Security Hub To enable AWS Security Hub:\n Log into your Cloud9 Workspace\n Run the following command (no output will be generated)\naws securityhub enable-security-hub --enable-default-standards Log into your AWS account with your browser and then browse to the AWS Security Hub.\nIf you see the Summary web page, it means its enabled in your account. You can skip to the Step2 below.\n  You may see a temporary red warning about AWS Config not being appropriately enabled, but it will disappear on its own once the Security Hub detects that the activation has been made. It has no relation to the use of Sysdig CloudConnector.\n Then, click '**Enable Security Hub**'. After this, the _\"Summary\"_ page for Security Hub will be shown. In the \u0026ldquo;Welcome to AWS Security Hub\u0026rdquo; page, you can indicate which security standard controls you want to enable, or accept the default. These controls are part of the default AWS Security Hub mechanism, and they are not related to the detections that Sysdig CloudConnector is going to find for you.\n -- Step 2. Install the CloudConnector To install this tool, we will be using a CloudFormation Template. Follow the steps below to install the Sysdig CloudConnector:\n Navigate to the CloudFormation template for Sysdig CloudConnector deployment. The template will preview in CloudFormation.  On the “Create stack” section, click the \u0026lsquo;Next\u0026rsquo; button to start setting up the template.  The “Specify stack details” section has no parameters for you to configure, so you can just press the Next button.  On “Configure stack options” screen, press the Next button.\nYou can optionally add tag keys and values to the deployment, but no further configuration is required. Finally, you will be presented with a summary of all the parameters you previously introduced. Please note that dedicated IAM roles will be created to perform the scanning. These roles follow the \u0026ldquo;least privilege principle\u0026rdquo; to enforce maximum security.\n  Finaally click the checkbox\n Then press the Create stack button\n  All ready! On the CloudFormation dashboard, you should see the template status is \u0026lsquo;CREATE_IN_PROGRESS\u0026rsquo;.\nThe creation process may take up to ten minutes. You\u0026rsquo;ll be using CloudConnector in Module 3. So, in the meantime, you can continue with this workshop. You can later revisit the CloudFormation section in AWS to check the status of the deployment. It will show as “CREATE_COMPLETE” once the deployment has completed successfully.\nStep summary \u0026ndash;\u0026gt;\n"
},
{
	"uri": "//localhost:1313/25_prework.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/50_module_3/52_setup_cloudtrail_runtime_security.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": "\u0026lt;!\u0026ndash; If you followed this workshop from the beginning then you should have deployed the CloudTrail CloudFormation Template earlier. If you didn\u0026rsquo;t, then go back and complete this step now Setup CloudTrail Runtime Security, however please note that this can take up to ten minutes to complete.\nTo check it has been deployed successfully, navigate to https://console.aws.amazon.com/cloudformation/ and search for CloudConnector. You should see it\u0026rsquo;s status is CREATE_COMPLETE.\n\u0026ndash;\u0026gt; \u0026ndash;\u0026gt;\n"
},
{
	"uri": "//localhost:1313/categories.html",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/tags.html",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]